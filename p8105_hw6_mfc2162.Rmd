---
title: "p8105_hw6_mfc2162"
author: "Madeline Cannon"
date: "11/17/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}

library(tidyverse)
library(modelr)
set.seed(1)

```

# Problem 1

## Load and clean data

```{r}

birthweight = read_csv("./data/birthweight.csv") %>%
  mutate(babysex = as.factor(recode(babysex, "1" = "male", "2" = "female"))) %>%
  mutate(frace = as.factor(recode(frace, "1" = "White",
                                          "2" = "Black",
                                          "3" = "Asian",
                                          "4" = "Puerto Rican",
                                          "8" = "Other",
                                          "9" = "Unknown"))) %>%
  mutate(frace = relevel(frace, "White")) %>%
  mutate(malform = as.factor(recode(malform, "0" = "absent", "1" = "present"))) %>%
  mutate(mrace = as.factor(recode(mrace, "1" = "White",
                                          "2" = "Black",
                                          "3" = "Asian",
                                          "4" = "Puerto Rican",
                                          "8" = "Other",
                                          "9" = "Unknown"))) %>%
  mutate(mrace = relevel(mrace, "White"))

```


## Build model

Birthweight is continuous, so I'll use a linear regression model.

Delivery weight can be directly calculated using pre-pregnancy weight and weight gain, so these three variables will be collinear. Similarly, pre-pregnancy BMI can be directly calculated using pre-pregnancy weight and height. To avoid collinearity, I will only include delivery weight and pre-pregancy BMI, since I believe these two variables will provide the most useful information for predicting birthweight.

#### Univariate analyses

First I'll do univariate analyses for each variable. I'll also plot continous variables against birthweight to check if the association is linear and if there are outliers.

```{r}

#babysex
fit = lm(bwt ~ babysex, data = birthweight)
summary(fit)

#bhead
fit = lm(bwt ~ bhead, data = birthweight)
summary(fit)
#Check for linearity and outliers
ggplot(data=birthweight, aes(x=bhead, y=bwt)) + geom_point() + geom_smooth()
#Remove outlier
birthweight = birthweight %>% filter(!(bwt == 2807 & bhead == 22))

#blength
fit = lm(bwt ~ blength, data = birthweight)
summary(fit)
#Check for linearity and outliers
ggplot(data=birthweight, aes(x=blength, y=bwt)) + geom_point() + geom_smooth()
#Remove outlier
birthweight = birthweight %>% filter(!(bwt == 3459 & blength == 20))

#delwt
fit = lm(bwt ~ delwt, data = birthweight)
summary(fit)
#Check for linearity and outliers
ggplot(data=birthweight, aes(x=delwt, y=bwt)) + geom_point() + geom_smooth()
#Not linear, use categorical variable
birthweight = birthweight %>%
  mutate(delwt_cat = cut(delwt, c(85, 115, 135, 155, 335))) %>%
  mutate(delwt_cat = relevel(delwt_cat, "(135,155]"))
fit = lm(bwt ~ delwt_cat, data = birthweight)
summary(fit)

#fincome
fit = lm(bwt ~ fincome, data = birthweight)
summary(fit)
#Check for linearity and outliers
ggplot(data=birthweight, aes(x=fincome, y=bwt)) + geom_point() + geom_smooth()

#frace
fit = lm(bwt ~ frace, data = birthweight)
summary(fit)

#gaweeks
fit = lm(bwt ~ gaweeks, data = birthweight)
summary(fit)
#Check for linearity and outliers
ggplot(data=birthweight, aes(x=gaweeks, y=bwt)) + geom_point() + geom_smooth()
#Not linear, use categorical variable
birthweight = birthweight %>%
  mutate(gaweeks_cat = cut(gaweeks, c(17, 30, 35, 40, 52))) %>%
  mutate(gaweeks_cat = relevel(gaweeks_cat, "(35,40]"))
fit = lm(bwt ~ gaweeks_cat, data = birthweight)
summary(fit)
#Categorical has lower adjusted R-squared, keep linear version

#malform
fit = lm(bwt ~ malform, data = birthweight)
summary(fit)

#menarche
fit = lm(bwt ~ menarche, data = birthweight)
summary(fit)
#Remove impossible observations
birthweight = birthweight %>% filter(!(menarche == 0 | menarche == 5))
#Check for linearity and outliers
ggplot(data=birthweight, aes(x=menarche, y=bwt)) + geom_point() + geom_smooth()

#momage
fit = lm(bwt ~ momage, data = birthweight)
summary(fit)
#Check for linearity and outliers
ggplot(data=birthweight, aes(x=momage, y=bwt)) + geom_point() + geom_smooth()
#Not linear, use categorical variable
birthweight = birthweight %>%
  mutate(momage_cat = cut(momage, c(11, 15, 20, 35, 45))) %>%
  mutate(momage_cat = relevel(momage_cat, "(15,20]"))
fit = lm(bwt ~ momage_cat, data = birthweight)
summary(fit)

#mrace
fit = lm(bwt ~ mrace, data = birthweight)
summary(fit)

#parity
fit = lm(bwt ~ parity, data = birthweight)
summary(fit)
#Check for linearity and outliers
ggplot(data=birthweight, aes(x=parity, y=bwt)) + geom_point() + geom_smooth()

#pnumlbw
fit = lm(bwt ~ pnumlbw, data = birthweight)
summary(fit)

#pnumgsa
fit = lm(bwt ~ pnumsga, data = birthweight)
summary(fit)

#ppbmi
fit = lm(bwt ~ ppbmi, data = birthweight)
summary(fit)
#Check for linearity and outliers
ggplot(data=birthweight, aes(x=ppbmi, y=bwt)) + geom_point() + geom_smooth()

#smoken
fit = lm(bwt ~ smoken, data = birthweight)
summary(fit)
#Check for linearity and outliers
ggplot(data=birthweight, aes(x=smoken, y=bwt)) + geom_point() + geom_smooth()
#Not linear, use categorical variable
birthweight = birthweight %>%
  mutate(smoken_cat = cut(smoken, c(-1, 0, 40, 61)))
fit = lm(bwt ~ smoken_cat, data = birthweight)
summary(fit)

```


#### Multivariable model building

I will exclude malform and parity from the model because their p-values were > 0.25 in the univariate analyses. pnumlbw and pnumsgsa had the same value for all observations, so I'll exclude them as well.

delwt, momage, and smoken were not linearly associated with birthweight, so I created categorical versions to use instead.

I'll start with all the remaining variables and remove them one at a time based on their p-values until all p-values are < 0.10.

```{r}

fit = lm(bwt ~ babysex + bhead + blength + delwt_cat + fincome + frace + gaweeks + menarche + momage_cat + mrace + ppbmi + smoken_cat, data = birthweight)
summary(fit)

#Remove frace
fit = lm(bwt ~ babysex + bhead + blength + delwt_cat + fincome + gaweeks + menarche + momage_cat + mrace + ppbmi + smoken_cat, data = birthweight)
summary(fit)

#Remove menarche
fit = lm(bwt ~ babysex + bhead + blength + delwt_cat + fincome + gaweeks + momage_cat + mrace + ppbmi + smoken_cat, data = birthweight)
summary(fit)

#Collapse smoken categories
birthweight = birthweight %>%
  mutate(smoken_cat = cut(smoken, c(-1, 0, 61)))
fit = lm(bwt ~ babysex + bhead + blength + delwt_cat + fincome + gaweeks + momage_cat + mrace + ppbmi + smoken_cat, data = birthweight)
summary(fit)

#Collapse momage categories
birthweight = birthweight %>%
  mutate(momage_cat = cut(momage, c(11, 15, 35, 45))) %>%
  mutate(momage_cat = relevel(momage_cat, "(15,35]"))
fit = lm(bwt ~ babysex + bhead + blength + delwt_cat + fincome + gaweeks + momage_cat + mrace + ppbmi + smoken_cat, data = birthweight)
summary(fit)

```

All remaining continuous variables have p-values < 0.10 and all remaining categorical variables have at least one category with p < 0.10.

The final model includes baby's sex, baby's head circumference, baby's length, mother's delivery weight (categorical), family income, gestational age, mother's age (categorical), mother's race, mother's pre-pregnancy BMI, and whether the mother smoked on average at least one cigarette per day during pregnancy (binary).

#### Plot predictions and residuals

```{r}

birthweight = birthweight %>%
                add_residuals(fit) %>%
                add_predictions(fit)

ggplot(data=birthweight, aes(x=pred, y=resid)) + geom_point()

```


## Compare to other models

```{r}

my_model = lm(bwt ~ babysex + bhead + blength + delwt_cat + fincome + gaweeks + momage_cat + mrace + ppbmi + smoken_cat, data = birthweight)

model2 = lm(bwt ~ blength + gaweeks, data=birthweight)

model3 = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data=birthweight)

cv_df =
  crossv_mc(birthweight, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df %>% 
  mutate(my_mod  = map(train, ~my_model),
         mod2     = map(train, ~model2),
         mod3  = map(train, ~model3)) %>% 
  mutate(rmse_my_mod = map2_dbl(my_mod, test, ~rmse(model = .x, data = .y)),
         rmse_mod2    = map2_dbl(mod2, test, ~rmse(model = .x, data = .y)),
         rmse_mod3 = map2_dbl(mod3, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()

```

My model is the most accurate. The third model including head circumerence, length, sex, and the interactions between them is close, while the second model containing only length and gestational age is much worse.


# Problem 2

## Load data

```{r}

weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

```


## Generate 5000 bootstrapped samples

```{r}

samples = weather_df %>% modelr::bootstrap(n = 5000)

boot_straps_tidy =
  samples %>% 
  mutate(
    models = map(strap, ~ lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy)) %>% 
  select(results) %>% 
  unnest(results) %>%
  select(term, estimate)

boot_straps_broom =
  samples %>% 
  mutate(
    models = map(strap, ~ lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::glance)) %>% 
  select(results) %>% 
  unnest(results) %>%
  select(r.squared)

for (i in 1:10000) {
  boot_straps_tidy[i, "sample_id"] = ceiling(i/2)
}

boot_straps_tidy = pivot_wider(boot_straps_tidy,
                               names_from = "term",
                               values_from = "estimate")

for (i in 1:5000) {
  boot_straps_broom[i, "sample_id"] = i
}

boot_straps = inner_join(boot_straps_broom, boot_straps_tidy, by = "sample_id")

for (i in 1:5000) {
  boot_straps[i, "b0"] = boot_straps[i, "(Intercept)"]
}

boot_straps = boot_straps %>%
  mutate(log_b0_b1 = log(b0 * tmin)) %>%
  select(sample_id, log_b0_b1, r.squared)

```


## Plot distribution of estimates

#### Density of log(B0*B1)

```{r}

ggplot(boot_straps, aes(x = log_b0_b1)) + geom_density() + xlab("log(B0*B1)")

```

log(B0*B1) is normally distriubted, with a mean of about 2.02.


#### Density of r squared

```{r}

ggplot(boot_straps, aes(x = r.squared)) + geom_density() + xlab("r squared")

```

R squared is slightly left-skewed, with a mean of about 0.91.


## 95% Confidence Intervals

```{r}

quantile(pull(boot_straps, log_b0_b1), probs=c(0.025, 0.975))
quantile(pull(boot_straps, r.squared), probs=c(0.025, 0.975))

```

The 95% confidence interval for log(B0*B1) is (1.96, 2.06).
The 95% confidence interval for r squared is (0.89, 0.93).